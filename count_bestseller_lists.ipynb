{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting references to bestsellers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error Foxton, E us nan\n",
      "error Burnett, Frances Hodgson us uk\n",
      "error Du Maurier, George uk nan\n",
      "error Thurston, Katherine ir uk\n",
      "error Joyce, James ir uk\n",
      "error Blasco Ibáñez, Vicente es spanish\n",
      "error Mundy, Talbot us uk\n",
      "error Arlen, Michael uk us\n",
      "error Fallada, Hans ger german\n"
     ]
    }
   ],
   "source": [
    "# degrees_of_bestseller.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "pseudonyms = dict()\n",
    "with open('pseudonyms.csv', encoding = 'utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        pseudonyms[row['pseudonym']] = row['ourname']\n",
    "\n",
    "prominence = Counter()\n",
    "namestocheck = dict()\n",
    "\n",
    "def nameinitial(astring):\n",
    "    if ',' in astring:\n",
    "        parts = astring.split(',')\n",
    "        name = parts[0]\n",
    "        if len(parts[0]) > 0:\n",
    "            parts[1] = parts[1].strip()\n",
    "            initial = parts[1][0]\n",
    "        else:\n",
    "            initial = ''\n",
    "    else:\n",
    "        name = astring\n",
    "        initial = ''\n",
    "\n",
    "    return name, initial\n",
    "\n",
    "def normalize_author(author):\n",
    "    global pseudonyms\n",
    "    author = author.strip(', .')\n",
    "    if author.startswith('Bront') and author.endswith('lotte'):\n",
    "        author = \"Brontë, Charlotte\"\n",
    "        # because bad things happen to umlauts sometimes\n",
    "    if author in pseudonyms:\n",
    "        author = pseudonyms[author]\n",
    "        \n",
    "    return author\n",
    "\n",
    "authorset = set()\n",
    "nationalities = dict()\n",
    "uslists = Counter()\n",
    "uklist = Counter()\n",
    "reviews = Counter()\n",
    "\n",
    "existingbest = pd.read_csv('/Users/tunder/Dropbox/GenreProject/python/reception/sales/bestsellermetadata.csv')\n",
    "for i in existingbest.index:\n",
    "    auth = normalize_author(existingbest.loc[i, 'author'])\n",
    "    if auth in pseudonyms:\n",
    "        auth = pseudonyms[auth]\n",
    "    sales = existingbest.loc[i, 'sales']\n",
    "    date = int(existingbest.loc[i, 'earliestdate'])\n",
    "    # if date < 1901 and sales == 'best':\n",
    "    #     uslists[auth] += 1\n",
    "    name, initial = nameinitial(auth)\n",
    "    namestocheck[(name, initial)] = auth\n",
    "    authorset.add(auth)\n",
    "    nationality = existingbest.loc[i, 'nationality']\n",
    "    nationalities[auth] = nationality\n",
    "\n",
    "with open('bestsellersources/HackettEBS.csv', encoding = 'utf-8') as f:\n",
    "    recordids = set()\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row['recordid'] in recordids:\n",
    "            continue\n",
    "        else:\n",
    "            auth = row['author'].strip('., ')\n",
    "            date = int(row['date'])\n",
    "            if date > 1849:\n",
    "                uklist [auth] += 1\n",
    "                authorset.add(auth)\n",
    "\n",
    "with open('bestsellersources/QDLeavisOutline.csv', encoding = 'utf-8') as f:\n",
    "    recordids = set()\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row['recordid'] in recordids:\n",
    "            continue\n",
    "        else:\n",
    "            auth = normalize_author(row['author'])\n",
    "            date = int(row['date'])\n",
    "            if date > 1849:\n",
    "                uklist[auth] += 1\n",
    "                authorset.add(auth)\n",
    "\n",
    "with open('bestsellersources/AltickECReaderFicPoe.csv', encoding = 'utf-8') as f:\n",
    "    recordids = set()\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row['recordid'] in recordids:\n",
    "            continue\n",
    "        elif row['Jgenre'] != 'fic':\n",
    "            continue\n",
    "        else:\n",
    "            auth = normalize_author(row['author'])\n",
    "            date = int(row['firstpub'])\n",
    "            if date > 1849:\n",
    "                uklist[auth] += 1\n",
    "                authorset.add(auth)\n",
    "\n",
    "with open('bestsellersources/MottGoldenMultitudes.csv', encoding = 'utf-8') as f:\n",
    "    recordids = set()\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        auth = normalize_author(row['author'])\n",
    "        date = int(row['date'])\n",
    "        if date > 1849:\n",
    "            uslists[auth] += 1\n",
    "            authorset.add(auth)\n",
    "\n",
    "rows = []\n",
    "for year in range (1895, 1901):\n",
    "    path = 'bestsellersources/Hackett' + str(year) + '.csv'\n",
    "    with open(path, encoding = 'utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        fields = reader.fieldnames\n",
    "        lastauth = 'mmmmm'\n",
    "        lasttitle = 'mmmmm'\n",
    "        for row in reader:\n",
    "            author = normalize_author(row['author'])\n",
    "            if len(author) < 3:\n",
    "                continue\n",
    "            if author.startswith(lastauth):\n",
    "                continue\n",
    "            title = row['title'].strip(', .')\n",
    "            if title.startswith(lasttitle):\n",
    "                continue\n",
    "            if len(author) > 4:\n",
    "                lastauth = author[0:4]\n",
    "            if len(title) > 4:\n",
    "                lasttitle = title[0:4]\n",
    "            if year < 1901:\n",
    "                uslists[author] += 1\n",
    "                authorset.add(auth)\n",
    "                rows.append(row)\n",
    "\n",
    "mapping = dict()\n",
    "\n",
    "with open('/Users/tunder/Dropbox/raship/ted/code/new_unsworth_bestsellers.csv', encoding = 'utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        year = int(row['year'])\n",
    "        if year > 1949:\n",
    "            continue\n",
    "        auth = normalize_author(row['author'])\n",
    "        if auth in authorset:\n",
    "            uslists[auth] += 1\n",
    "        elif auth in mapping:\n",
    "            auth = mapping[auth]\n",
    "            uslists[auth] += 1\n",
    "            authorset.add(auth)\n",
    "        else:\n",
    "            name, initial = nameinitial(auth)\n",
    "            if (name, initial) in namestocheck:\n",
    "\n",
    "                if auth == namestocheck[(name, initial)]:\n",
    "                    uslists[auth] += 1\n",
    "                else:\n",
    "                    # print(auth)\n",
    "                    # print(name, initial)\n",
    "                    # print(namestocheck[(name, initial)])\n",
    "                    user = 'y'\n",
    "                    if user == 'y':\n",
    "                        uslists[namestocheck[(name, initial)]] += 1\n",
    "                        mapping[auth] = namestocheck[(name, initial)]\n",
    "                        authorset.add(auth)\n",
    "                    else:\n",
    "                        uslists[auth] += 1\n",
    "                        authorset.add(auth)\n",
    "            else:\n",
    "                uslists[auth] += 1\n",
    "                authorset.add(auth)\n",
    "\n",
    "prestigemeta = pd.read_csv('../fiction/prestigeficmeta.csv')\n",
    "for i in prestigemeta.index:\n",
    "    reviewed = prestigemeta.loc[i, 'tags']\n",
    "    auth = normalize_author(prestigemeta.loc[i, 'author'])\n",
    "    authorset.add(auth)\n",
    "    nationality = prestigemeta.loc[i, 'nationality']\n",
    "    if auth not in nationalities:\n",
    "        nationalities[auth] = nationality\n",
    "    else:\n",
    "        if nationality != nationalities[auth] and not pd.isnull(nationality):\n",
    "            print('error', auth, nationality, nationalities[auth])\n",
    "            # but treat prestigemeta as the final authority\n",
    "            nationalities[auth] = nationality\n",
    "    if reviewed == 'elite':\n",
    "        reviews[auth] += 1\n",
    "        # alreadycounted.add(auth)\n",
    "\n",
    "with open('../bayespost/clivebloombestsellers.csv', encoding = 'utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        auth = normalize_author(row['author'])\n",
    "        uklist[auth] += 2\n",
    "        # Note that this source gets +2, while all the others get +1.\n",
    "        # That's because Bloom is usually mentioning more than one book\n",
    "        # for each author, and never mentions authors more than once.\n",
    "        # It's more of a \"career award.\"\n",
    "        authorset.add(auth)\n",
    "\n",
    "isuk = dict()\n",
    "isus = dict()\n",
    "isother = dict()\n",
    "\n",
    "for k, v in nationalities.items():\n",
    "    if v == 'us' or v == 'ca':\n",
    "        isus[k] = 1\n",
    "    elif v == 'uk' or v == 'ir':\n",
    "        isuk[k] = 1\n",
    "    else:\n",
    "        isother[k] = 1\n",
    "\n",
    "prepframe = dict()\n",
    "\n",
    "prepframe['uslists'] = uslists\n",
    "prepframe['reviews'] = reviews\n",
    "prepframe['uklist'] = uklist\n",
    "prepframe['nationality'] = nationalities\n",
    "prepframe['is_us'] = isus\n",
    "prepframe['is_uk'] = isuk\n",
    "prepframe['is_other'] = isother\n",
    "\n",
    "authorset.remove('<blank>')\n",
    "df = pd.DataFrame(prepframe, index = list(authorset))\n",
    "df = df.fillna(0)\n",
    "df['salesevidence'] = df.uslists + df.uklist\n",
    "df.to_csv('../bayespost/counted_bestsellers.csv', index_label = 'author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1177"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
